{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07bbf858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc04f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Corona_NLP_train.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b586ff0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "0          3799       48751                        London  16-03-2020   \n",
       "1          3800       48752                            UK  16-03-2020   \n",
       "2          3801       48753                     Vagabonds  16-03-2020   \n",
       "3          3802       48754                           NaN  16-03-2020   \n",
       "4          3803       48755                           NaN  16-03-2020   \n",
       "...         ...         ...                           ...         ...   \n",
       "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
       "41153     44952       89904                           NaN  14-04-2020   \n",
       "41154     44953       89905                           NaN  14-04-2020   \n",
       "41155     44954       89906                           NaN  14-04-2020   \n",
       "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1      advice Talk to your neighbours family to excha...            Positive  \n",
       "2      Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3      My food stock is not the only one which is emp...            Positive  \n",
       "4      Me, ready to go at supermarket during the #COV...  Extremely Negative  \n",
       "...                                                  ...                 ...  \n",
       "41152  Airline pilots offering to stock supermarket s...             Neutral  \n",
       "41153  Response to complaint not provided citing COVI...  Extremely Negative  \n",
       "41154  You know itÂs getting tough when @KameronWild...            Positive  \n",
       "41155  Is it wrong that the smell of hand sanitizer i...             Neutral  \n",
       "41156  @TartiiCat Well new/used Rift S are going for ...            Negative  \n",
       "\n",
       "[41157 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cbc4aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Neutral', 'Positive', 'Extremely Negative', 'Negative',\n",
       "       'Extremely Positive'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc2cd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8\n",
      "advice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order\n",
      "Coronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P\n"
     ]
    }
   ],
   "source": [
    "for i in df[\"OriginalTweet\"][:3]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cf826c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,[\"OriginalTweet\", \"Sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8279f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"text\", \"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff03bbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03a966b",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d765235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6d12588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab5dbf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"filtered_text\"] = df[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7c46397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>menyrbie philgahan chrisitv  and  and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>coronavirus australia woolworths to give elder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>me ready to go at supermarket during the  outb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           sentiment  \\\n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n",
       "1  advice Talk to your neighbours family to excha...            Positive   \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive   \n",
       "3  My food stock is not the only one which is emp...            Positive   \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative   \n",
       "\n",
       "                                       filtered_text  \n",
       "0             menyrbie philgahan chrisitv  and  and   \n",
       "1  advice talk to your neighbours family to excha...  \n",
       "2  coronavirus australia woolworths to give elder...  \n",
       "3  my food stock is not the only one which is emp...  \n",
       "4  me ready to go at supermarket during the  outb...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c78b9208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da819539",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "174911a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/yahor/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73784f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"filtered_text\"] = df[\"filtered_text\"].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbf11c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[menyrbie, philgahan, chrisitv, and, and]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[advice, talk, to, your, neighbours, family, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[coronavirus, australia, woolworths, to, give,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[my, food, stock, is, not, the, only, one, whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>[me, ready, to, go, at, supermarket, during, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           sentiment  \\\n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n",
       "1  advice Talk to your neighbours family to excha...            Positive   \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive   \n",
       "3  My food stock is not the only one which is emp...            Positive   \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative   \n",
       "\n",
       "                                       filtered_text  \n",
       "0          [menyrbie, philgahan, chrisitv, and, and]  \n",
       "1  [advice, talk, to, your, neighbours, family, t...  \n",
       "2  [coronavirus, australia, woolworths, to, give,...  \n",
       "3  [my, food, stock, is, not, the, only, one, whi...  \n",
       "4  [me, ready, to, go, at, supermarket, during, t...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6206f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(x):\n",
    "    arr = []\n",
    "    for word in x:\n",
    "        if word not in stopword:\n",
    "           arr.append(word)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5afda79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"filtered_text\"] = df[\"filtered_text\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84637e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[menyrbie, philgahan, chrisitv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[advice, talk, neighbours, family, exchange, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[coronavirus, australia, woolworths, give, eld...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[food, stock, one, empty, please, dont, panic,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>[ready, go, supermarket, outbreak, im, paranoi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           sentiment  \\\n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n",
       "1  advice Talk to your neighbours family to excha...            Positive   \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive   \n",
       "3  My food stock is not the only one which is emp...            Positive   \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative   \n",
       "\n",
       "                                       filtered_text  \n",
       "0                    [menyrbie, philgahan, chrisitv]  \n",
       "1  [advice, talk, neighbours, family, exchange, p...  \n",
       "2  [coronavirus, australia, woolworths, give, eld...  \n",
       "3  [food, stock, one, empty, please, dont, panic,...  \n",
       "4  [ready, go, supermarket, outbreak, im, paranoi...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a5ea956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9127ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "snowball_stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a117a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/yahor/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2f9b6f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(x):\n",
    "    arr = []\n",
    "    for word in x:\n",
    "        arr.append(wordnet_lemmatizer.lemmatize(word))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9edbb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(x):\n",
    "    arr = []\n",
    "    for word in x:\n",
    "        arr.append(snowball_stemmer.stem(word))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3cef3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_stemming(x):\n",
    "    arr = lemma(x)\n",
    "    arr = stemming(arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac731a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemma_text\"] = df[\"filtered_text\"].apply(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17168fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stemming_text\"] = df[\"filtered_text\"].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c617057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lemma_stemming_text\"] = df[\"filtered_text\"].apply(lemma_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10ec58eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>stemming_text</th>\n",
       "      <th>lemma_stemming_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[menyrbie, philgahan, chrisitv]</td>\n",
       "      <td>[menyrbie, philgahan, chrisitv]</td>\n",
       "      <td>[menyrbi, philgahan, chrisitv]</td>\n",
       "      <td>[menyrbi, philgahan, chrisitv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[advice, talk, neighbours, family, exchange, p...</td>\n",
       "      <td>[advice, talk, neighbour, family, exchange, ph...</td>\n",
       "      <td>[advic, talk, neighbour, famili, exchang, phon...</td>\n",
       "      <td>[advic, talk, neighbour, famili, exchang, phon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[coronavirus, australia, woolworths, give, eld...</td>\n",
       "      <td>[coronavirus, australia, woolworth, give, elde...</td>\n",
       "      <td>[coronavirus, australia, woolworth, give, elde...</td>\n",
       "      <td>[coronavirus, australia, woolworth, give, elde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[food, stock, one, empty, please, dont, panic,...</td>\n",
       "      <td>[food, stock, one, empty, please, dont, panic,...</td>\n",
       "      <td>[food, stock, one, empti, pleas, dont, panic, ...</td>\n",
       "      <td>[food, stock, one, empti, pleas, dont, panic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>[ready, go, supermarket, outbreak, im, paranoi...</td>\n",
       "      <td>[ready, go, supermarket, outbreak, im, paranoi...</td>\n",
       "      <td>[readi, go, supermarket, outbreak, im, paranoi...</td>\n",
       "      <td>[readi, go, supermarket, outbreak, im, paranoi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           sentiment  \\\n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n",
       "1  advice Talk to your neighbours family to excha...            Positive   \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive   \n",
       "3  My food stock is not the only one which is emp...            Positive   \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative   \n",
       "\n",
       "                                       filtered_text  \\\n",
       "0                    [menyrbie, philgahan, chrisitv]   \n",
       "1  [advice, talk, neighbours, family, exchange, p...   \n",
       "2  [coronavirus, australia, woolworths, give, eld...   \n",
       "3  [food, stock, one, empty, please, dont, panic,...   \n",
       "4  [ready, go, supermarket, outbreak, im, paranoi...   \n",
       "\n",
       "                                          lemma_text  \\\n",
       "0                    [menyrbie, philgahan, chrisitv]   \n",
       "1  [advice, talk, neighbour, family, exchange, ph...   \n",
       "2  [coronavirus, australia, woolworth, give, elde...   \n",
       "3  [food, stock, one, empty, please, dont, panic,...   \n",
       "4  [ready, go, supermarket, outbreak, im, paranoi...   \n",
       "\n",
       "                                       stemming_text  \\\n",
       "0                     [menyrbi, philgahan, chrisitv]   \n",
       "1  [advic, talk, neighbour, famili, exchang, phon...   \n",
       "2  [coronavirus, australia, woolworth, give, elde...   \n",
       "3  [food, stock, one, empti, pleas, dont, panic, ...   \n",
       "4  [readi, go, supermarket, outbreak, im, paranoi...   \n",
       "\n",
       "                                 lemma_stemming_text  \n",
       "0                     [menyrbi, philgahan, chrisitv]  \n",
       "1  [advic, talk, neighbour, famili, exchang, phon...  \n",
       "2  [coronavirus, australia, woolworth, give, elde...  \n",
       "3  [food, stock, one, empti, pleas, dont, panic, ...  \n",
       "4  [readi, go, supermarket, outbreak, im, paranoi...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8aaca7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dda7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3267b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment\"] = le.fit_transform(df[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2304bfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>stemming_text</th>\n",
       "      <th>lemma_stemming_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>3</td>\n",
       "      <td>[menyrbie, philgahan, chrisitv]</td>\n",
       "      <td>[menyrbie, philgahan, chrisitv]</td>\n",
       "      <td>[menyrbi, philgahan, chrisitv]</td>\n",
       "      <td>[menyrbi, philgahan, chrisitv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>4</td>\n",
       "      <td>[advice, talk, neighbours, family, exchange, p...</td>\n",
       "      <td>[advice, talk, neighbour, family, exchange, ph...</td>\n",
       "      <td>[advic, talk, neighbour, famili, exchang, phon...</td>\n",
       "      <td>[advic, talk, neighbour, famili, exchang, phon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>4</td>\n",
       "      <td>[coronavirus, australia, woolworths, give, eld...</td>\n",
       "      <td>[coronavirus, australia, woolworth, give, elde...</td>\n",
       "      <td>[coronavirus, australia, woolworth, give, elde...</td>\n",
       "      <td>[coronavirus, australia, woolworth, give, elde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>4</td>\n",
       "      <td>[food, stock, one, empty, please, dont, panic,...</td>\n",
       "      <td>[food, stock, one, empty, please, dont, panic,...</td>\n",
       "      <td>[food, stock, one, empti, pleas, dont, panic, ...</td>\n",
       "      <td>[food, stock, one, empti, pleas, dont, panic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>0</td>\n",
       "      <td>[ready, go, supermarket, outbreak, im, paranoi...</td>\n",
       "      <td>[ready, go, supermarket, outbreak, im, paranoi...</td>\n",
       "      <td>[readi, go, supermarket, outbreak, im, paranoi...</td>\n",
       "      <td>[readi, go, supermarket, outbreak, im, paranoi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  \\\n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...          3   \n",
       "1  advice Talk to your neighbours family to excha...          4   \n",
       "2  Coronavirus Australia: Woolworths to give elde...          4   \n",
       "3  My food stock is not the only one which is emp...          4   \n",
       "4  Me, ready to go at supermarket during the #COV...          0   \n",
       "\n",
       "                                       filtered_text  \\\n",
       "0                    [menyrbie, philgahan, chrisitv]   \n",
       "1  [advice, talk, neighbours, family, exchange, p...   \n",
       "2  [coronavirus, australia, woolworths, give, eld...   \n",
       "3  [food, stock, one, empty, please, dont, panic,...   \n",
       "4  [ready, go, supermarket, outbreak, im, paranoi...   \n",
       "\n",
       "                                          lemma_text  \\\n",
       "0                    [menyrbie, philgahan, chrisitv]   \n",
       "1  [advice, talk, neighbour, family, exchange, ph...   \n",
       "2  [coronavirus, australia, woolworth, give, elde...   \n",
       "3  [food, stock, one, empty, please, dont, panic,...   \n",
       "4  [ready, go, supermarket, outbreak, im, paranoi...   \n",
       "\n",
       "                                       stemming_text  \\\n",
       "0                     [menyrbi, philgahan, chrisitv]   \n",
       "1  [advic, talk, neighbour, famili, exchang, phon...   \n",
       "2  [coronavirus, australia, woolworth, give, elde...   \n",
       "3  [food, stock, one, empti, pleas, dont, panic, ...   \n",
       "4  [readi, go, supermarket, outbreak, im, paranoi...   \n",
       "\n",
       "                                 lemma_stemming_text  \n",
       "0                     [menyrbi, philgahan, chrisitv]  \n",
       "1  [advic, talk, neighbour, famili, exchang, phon...  \n",
       "2  [coronavirus, australia, woolworth, give, elde...  \n",
       "3  [food, stock, one, empti, pleas, dont, panic, ...  \n",
       "4  [readi, go, supermarket, outbreak, im, paranoi...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1fbff7",
   "metadata": {},
   "source": [
    "# Test DataFrame Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59d09b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"Corona_NLP_test.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "086fcabd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1545085199.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[36], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    for word i\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x):\n",
    "    arr = []\n",
    "    for word i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406aedcb",
   "metadata": {},
   "source": [
    "# Building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d505677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e96ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9537cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb405a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8a7e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1c93de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
